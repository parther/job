信访爬虫项目-分析 http://t.cn/RnZRJxd
# 
目的：
从天涯论坛爬取上访用户的相关内容
完成时间：
0102 - 0206 周二
成果：
代码；数据库表；数据库表说明
计划:
0319 周一 着手解决按时间提取的问题
0320 周二 user_list，连接数据库；其他表格，设置时间提取规则，连接数据库，更新规则；交给何老师

===
技术问题和总结 https://github.com/parther/others/blob/master/spider
搜索入口 http://search.tianya.cn/user?q=%E4%B8%8A%E8%AE%BF

=
# 更新：
每天7点自动更新搜索页第一页用户的数据
按照最后登录时间来更新数据库，尽量减少工作量

=
# 优化
策略：
1 命名符合中文习惯
2 尽量使用外调库封装常用函数 如数据库连接 后面再统一考虑
3 注释 统一添加
'#' 放在需要说明的代码上一行
4 爬取间隔 5-10秒 目前暂不考虑
5 数据库字段的格式及主键 没用到 后面再考虑

=
# 字段入库处理
天涯和微博 汇入同一个数据库，id自增会有重复的
? busi_petitioner resource` `weburl` 是什么意思
? busi_petitioner birthday 需要换成那种形式 
? busi_petitioner Create_time registration_date 如何理解
? busi_petitioner location换成city和province
? work_company 怎么会是 industry呢
-

? 游标的概念
http://www.runoob.com/python/python-mysql.html

===
# 表
爬虫尽量拿到原始数据，至于怎么用再做拼接
 
# 1 上访用户列表 user_list 4个字段 576条数据
用户id user_id 昵称nickname 个人主页homepage 最后登录时间last_login_time
-

=
# 2 上访用户个人信息表 user_info 17个字段 576条数据
user_id 昵称nickname 被封杀banned 等级level 等级标签level_label关注数follow_number 粉丝数followed_number 
积分point 主贴数post_number 回帖数reply_number
注册日期registration_date 生日birthday 地区location 行业industry 职业occupation 标签label 个人介绍self_introduction 

-
主贴数 回帖数 数据错误 http://www.tianya.cn/12188710/bbs?t=post 可能是有删帖
每100条数据采集

=
# 3 上访用户发帖列表 post_list 5个字段 共1136条数据 783条不重复数据 1条为nan
发帖id post_id  帖子链接post_url 帖子标题post_title 发帖板块post_section 用户id user_id
-
根据实际情况，只选择至多25条数据

=
# 4 上访用户发帖内容表 post_content 9个字段 共781条数据
发帖id post_id 帖子链接post_url 帖子标题post_title 帖子内容post_text 发布时间post_time 
点击数click_number 回复数click_reply_number 点赞数like_number 发帖终端post_terminal
? 打赏人数number_of_reward ? 总赏金total_reward


-
打赏人数number_of_reward 总赏金total_reward 暂时获取不到js，不抓取 http://bbs.tianya.cn/post-news-364310-1.shtml
图片暂时不爬取，图片是少数
? 将表3中的数据导入清洗去重以后再放入爬虫 存入mysql再考虑
? 考虑3和4同时抓取 代码优化再考虑
=

# 5 上访用户发帖的回帖表 post_reply 7个字段 7935数据
回帖id reply_id 帖子链接post_url 回帖内容reply_text 回帖时间reply_time 回帖人昵称reply_nickname 
回帖人主页reply_user_homepage 回帖终端reply_terminal 回帖楼层reply_order 发帖id post_id
-
? 尚未核对爬虫未爬取到的数据，可能3个左右 代码优化后再考虑
发给别人邮件，如果有需要说明的，最好附件中也加上文档

=
6 上访用户关注列表 follow_list 3个字段
userID 昵称follow_nickname 个人主页follow_homepage
-
结果去重的问题
设置为至多爬2页，大部分上访人不会有那么多的粉丝和关注

=
7 上访用户粉丝列表 followed_list 3个字段
userID 昵称followed_nickname 个人主页followed_homepage

=
8 上访用户回帖列表 reply_list 4个字段
用户id-userID 回帖id 帖子链接reply_url 标题reply_title 发帖板块reply_section
-

=
9 上访用户回帖内容表 reply 5个 
帖子链接reply_url 回帖内容reply_text 回帖时间reply_time 
回帖终端reply_terminal 回帖楼层reply_order
-
? 有的楼层被删除消失了，需要加一个字段判断报错
回复中的回复需要翻页的 暂不考虑  pyv8 https://www.zhihu.com/question/20626694/answer/15675919 Xhr

=
10 上访用户回帖针对的帖子表 post_reply 8个 未完成
帖子链接reply_url 标题reply_title 内容post_text 发布时间post_time 发帖终端post_terminal
点击数click_number 回复数click_reply_number 点赞数like_number
=
11 上访用户发帖的回复的回复表 reply_reply_post_content 7个字段 未完成
帖子链接reply_url 回帖内容reply_text 回帖人reply_userID
=
12 动态表 未完成
他的随记主要是由博文组成的



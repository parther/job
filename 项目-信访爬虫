# 目的：
从天涯论坛爬取上访用户的相关内容
完成时间：
0206 周二
考核：
所有内容能够爬取下来，梦圆，杨老师认同
=
# 计划:
0102-0106 熟悉爬虫，并且实现爬虫抓取天涯网页内容
0103 周三 跟着案例学爬虫并用Python实现它
0104 周四 更高级的爬虫案例并且实现
0105 周五 从天涯爬取内容；和嘉敏确定爬虫字段，并且统一格式；解决翻页的问题
0106 周六 实战，并且用更简洁的代码；再次尝试翻页的rule及其他方法
0106 周六 临时调整工作 协助怡婷整理文档
0108-0113 正式开始爬虫
0108 周一 实战爬取一级页面，并且用更简洁的代码；再次尝试翻页的rule及其他方法
0109 周二 复盘爬取经验；实现二级页面的爬取
0110 周三 天涯多页面二级页面的爬取。爬虫经验的复盘；爬一个页面
0111 周四 从实际出发，爬取二级页面，爬取最终页面
0112 周五 实现天涯单页多级页面的爬取v；爬取最终页的内容和评论v；下午4点跟梦圆讨论下
0113 周六 从实际出发，各级别页面小规模测试；大规模页面爬取，使用反扒措施；解决csv隔行等问题
0115-0120 大规模爬取
0115 周一 设置代理反爬，爬取info
0116 周二 设置代理反爬，爬取info
0117 周三 爬取post、reply、comment
0118 周四 再次解决各类问题
0119 周五 解决翻页获取的问题
0120 周六
-
0122-0127 大规模爬取
0122 周一 用meta解决翻页的问题
0123 周二 翻页加js爬取
0124 周三 停车总结
0125 周四 连接mysql
0126 周五 个人主页爬全
0127 周六 所有单页爬全
-
0131-0206 收工
0131 成果展示v；代码总结；优化；关注表；粉丝表
0201 周四 优化；关注表；粉丝表
0202 周五 页面5优化；关注表；粉丝表
-
0205-0209 结束吧
0205 回帖列表；回帖内容表；上访用户回帖针对的帖子表
0206 上访用户发帖的回复的回复表
0207 2上访用户个人信息表 主贴数 回帖数 放在一起解析；8上访用户回帖列表 截取出来的不对
0208 周四 优化考虑分析的问题
0209 周五 跑出所有的结果，看能否连接数据库
===
照片先不爬
回帖先不爬
能够爬取的内容固定下来。个人信息表 主贴 主贴回复
目的是为了掌握事情的发展路径
技术指导 https://github.com/parther/others/blob/master/spider
考虑数据的更新 上访用户贴的更新
命名规则
与信访局相结合，能否识别此人在信访局有记录
=
http://search.tianya.cn/user?q=%E4%B8%8A%E8%AE%BF
1 上访用户表 user_list 4个字段
userID 昵称nickname 个人主页homepage 最后登录时间last_login_time
-
? 能否设置自动翻页
? 用xpath清洗数据 last_login_time[i]

=
2 上访用户个人信息表 user_info 17个字段
userID 昵称nickname 等级level 等级标签level_label 被禁banned 关注数follow_number 粉丝followed_number 
积分point 注册日期registration_date 生日birthday 地区location 行业industry 职业occupation 标签tag 个人介绍self_introduction 
? 主贴数post_number ? 回帖数reply_number
-
? 主贴数 回帖数 能否放在一起解析
主贴数 回帖数 数据错误 http://www.tianya.cn/12188710/bbs?t=post

=
3 上访用户发帖列表 post_list 4个字段
userID 帖子链接post_url 标题post_title 板块post_section
-
根据实际情况，只选择至多25条数据

=
4 上访用户发帖内容表 post 8个字段
帖子链接post_url 标题post_title 内容post_text 发布时间post_time 
点击数click_number 回复数click_reply_number 点赞数like_number 发帖终端post_terminal
? 打赏人数number_of_reward ? 总赏金total_reward
-
打赏人数number_of_reward 总赏金total_reward 暂时获取不到js，不抓取 http://bbs.tianya.cn/post-news-364310-1.shtmlru
图片暂时不爬取，图片是少数
数据清洗 4个赞 点击：1955 回复：66 

=
5 上访用户发帖的回帖表 reply_post 7个字段
帖子链接post_url 回帖内容reply_text 回帖时间reply_time 回帖人昵称reply_nickname 回帖人主页reply_user_homepage
回帖终端reply_terminal 回帖楼层reply_order
-

=
6 上访用户关注列表 follow_list 3个字段
userID 昵称follow_nickname 个人主页follow_homepage
-
结果去重的问题
设置为至多爬2页，大部分上访人不会有那么多的粉丝和关注

=
7 上访用户粉丝列表 followed_list 3个字段
userID 昵称followed_nickname 个人主页followed_homepage

=

8 上访用户回帖列表 reply_list 4个字段
userID 帖子链接reply_url 标题reply_title 发帖板块reply_section
-
? id 提取出来的数字不对
=
9 上访用户回帖内容表 reply 5个 
帖子链接reply_url 回帖内容reply_text 回帖时间reply_time 
回帖终端reply_terminal 回帖楼层reply_order
-
? 有的楼层被删除消失了，需要加一个字段判断报错
回复中的回复需要翻页的 暂不考虑  pyv8 https://www.zhihu.com/question/20626694/answer/15675919 Xhr

=
10 上访用户回帖针对的帖子表 post_reply 8个 未完成
帖子链接reply_url 标题reply_title 内容post_text 发布时间post_time 发帖终端post_terminal
点击数click_number 回复数click_reply_number 点赞数like_number
=
11 上访用户发帖的回复的回复表 reply_reply_post_content 7个字段 未完成
帖子链接reply_url 回帖内容reply_text 回帖人reply_userID
=
12 动态表 未完成
他的随记主要是由博文组成的



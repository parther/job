# 目标：
爬取北京规范性文件，存入数据库
开始时间：0316 周五
计划完成时间：0330 周五
成果：爬虫代码；数据表
-
计划：
0323 周五 爬取所有的数据；解析入库

===
技术问题和总结 https://github.com/parther/others/blob/master/spider
爬取入口 http://zhengce.beijing.gov.cn/zhengce/197/1861/989831/index.html

===
# 爬虫
北京规范性文件 beijing_normative_documents
=
1 单位发布规范性文件表的链接的表 release_unit
unit_id 
级别level 单位unit 单位发布规范性文件表的链接release_url

=
2 规范性文件的链接表 post_url
post_url_id
发文链接post_url 发布时间publish_date 单位发布规范性文件表的链接release_url
-

mysql 命名规则 t_表名 info_id
join代替+ format代替%的用法
.strip('_|.')
换页有两种方法 xpath和根据页面的规则
将mysql表结构和数据给别人 server dataexport
参考刘总的数据表格式 
? 数据库中多了数据，为何没有去重 744 - 784
? 数据表为什么从785开始
编号默认从最后输入的位置开始
delete from post_url
=
3 规范性文件表 normative_documents
post_id 
发文机构post_agency 发文字号post_number	类别category	成文日期written_date	发布日期publish_date	实施日期implementation_date	
废止日期abolish_date	有效性effectiveness	标题title	正文text 发文链接post_url
-

4 规范性文件条目表 document_items
item_id 
发文字号post_number 标题title 法律法规名称law_name  章节序号chapter_number 条目序号item_number 条目内容item_content

===
# 入库
新的表格式入库


